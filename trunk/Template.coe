# ----------------------------------------------------------------------------------------
#                                     Data loading
# ----------------------------------------------------------------------------------------

# The alphabet to use:
# DNA, RNA or Protein
alphabet = DNA

# The sequence file to use (sequences must be aligned!)
sequence.file = myfile.mase
# The alignment format:
# Must be one of Mase, Fasta, Phylip, Clustal 
sequence.format = Mase
# Mase format option:
sequence.format_mase.site_selection =
# Phylip format options:
# interleaved or sequential:
sequence.format_phylip.order =
# classic or extended (PAML):
sequence.format_phylip.ext = 

#Sites to use:
# all, nogap or complete (=only resolved chars)
sequence.sites_to_use = nogap
# Specify a maximum amount of gaps: may be an absolute number or a percentage.
sequence.max_gap_allowed=100%

# Second file:
sequence.file2 = none
# All previous options can be set up for second file, just append '2' at option names.
# The default is to use options of file1 for file2.

# The tree file to use. Branch lengths are optional.
# Only newick format is supported.
tree.file = mytree.dnd

# ----------------------------------------------------------------------------------------
#                                     Model specification
# ----------------------------------------------------------------------------------------

# Available models.
# For proteins, the DCmutt method is used for JTT92 and DSO78.
# You can use the 'empirical' option to specify another model.
# JCnuc, K80, T92, HKY85, F84, TN93, GTR, JCprot, DSO78, JTT92 or empirical
model = HKY85
# Initial values for parameters:
#kappa (K80, T92, HKY85, F84)
#kappa1, kappa2 (TN93)
#theta (T92)
#piA, piT, piC and piG (HKY85, F84, TN93 and GTR)
#a,b,c,d,e (GTR)
kappa = 2.843
#Tell if we have to use observed frequencies as parameter values (for piA, piT, piG, piC and theta).
#For proteins, this is equivalent to the -F model family.
model.use_observed_freq = yes
#If empirical is set, specify the path where to find model (in PAML format).
model_empirical.file = 

# Rate Across Sites variation:
# gamma or constant
rate_distribution = gamma
# The gamma distribution's shape parameter
rate_distribution_gamma.alpha = 0.358
# Number of classes for discretization:
rate_distribution.classes_number = 4

# ----------------------------------------------------------------------------------------
#                                     Parameter estimation
# ----------------------------------------------------------------------------------------

# Should we reestimate likelihood parameters? Tree topology will not be optimized.
# (recommanded)
optimization = yes

# Method to use for optimizing numerical parameters:
# -NB (default) Newton-Raphson for branch lengths + Brent for other parameters
# -NND Newton-Raphson for all parameters, using numerical derivatives for non-branch lengths parameters.

optimization.method=NB

# Number of progressive steps to use in NB optimization (a value of 5 is often fine).
# 1 means no progressive optimization.
optimization_NB.nstep=1

# A file where to dump optimization steps (a file path or std for standard output)
optimization.profiler = myfile.profile
# idem for error or warning messages:
optimization.message_handler = myfile.messages
# Maximum number of likelihood evaluations:
optimization.max_number_f_eval = 1000000
# Parameters to ignore (there is currently no estimation methods for equilibrium frequencies)
optimization.ignore_parameter = piA,piC,piG,piT
# Precision to reach:
optimization.tolerance = 0.000001

# Should we write the optimized tree? none or file name.
output.tree.file = myfile.opt.dnd

# A file where site-specific information will be written (posterior rate, constant site, etc.):
output.infos = myfile.infos

# ----------------------------------------------------------------------------------------
#                                     Substitution vectors
# ----------------------------------------------------------------------------------------

# We may restart an analysis by specifying the already computed vectors:
input.vectors.file = none
# Otherwise, tell where to write vectors:
output.vectors.file = myfile.vec

# The method to use to compute vectors:
# One of
# - laplace: real mapping
# - simple: naive mapping (1 substitution if x<>y, 0 if x==y)
# - aadist: weighted mapping (proteins)
nijt = laplace
# Where to trunc the series (see article):
nijt_laplace.trunc = 10
nijt_aadist.type=grantham
nijt_aadist.sym=yes
# Should we average over all ancestral state (yes) or use ancestral states reconstruction (no) ?
nijt.average = yes
# Should we use pair-joint calculation (yes) or marginal (no) one?
nijt.joint = yes
#!!! The 2 previous options are mainly for method comparisons, see article.

# Should we write a tree with inner node names? none or file name.
output.tags.file = myfile.tags.dnd
# Write a file whith the correspondance between leaf names and ids.
output.tags.translation = myfile.tags.tln

# ----------------------------------------------------------------------------------------
#                                     Pairwise analysis
# ----------------------------------------------------------------------------------------

# correlation or covariance or none (only mapping):
statistic = correlation

# where to write the results:
statistic.output.file = myfile.sta

# Minimum statistic to write in file:
statistic.min = 0

# Only write pairs with minimum rate:
statistic.min_rate = 0
# Only write pairs with minimum rate class (first class is 0):
statistic.min_rate_class = 0
# Only write pairs with site rates that differ less than... (-1 -> write all pairs):
statistic.max_rate_diff = -1.
# Only write pairs with site rate classes that differ less than... (-1 -> write all pairs):
statistic.max_rate_class_diff = -1

# Null distribution of the statistic:

# Compute null distribution of statistics (takes some time!)
statistic.null = true

# CPU*RAM pair of sites will be simulated.
# increasing the RAM parameter speeds the program but need more memory
# increasing the CPU parameter slower the program but need less memory
statistic.null.nb_rep_CPU = 100
statistic.null.nb_rep_RAM = 1000

# Where to write the null distribution
statistic.null.output.file = myfile.null

# Should we write the null distribution has an histogram?
# Otherwise prints all similated pairs.
statistic.null.cumul = no
# Lower bound for histogram
statistic.null.lower =
# Upper bound for histogram
statistic.null.upper =
# Number of intervals
statistic.null.nb_int =

# ----------------------------------------------------------------------------------------
#                                     Clustering Analysis
# ----------------------------------------------------------------------------------------

# Distance to use: cor (correlation) or euclidian or none
clustering.distance=cor
# Tell is mapping should be normalized (each row (=branch) will be divided by its sum.
clustering.scale=no
# Clustering algorithm: only complete is supported for now.
clustering.method=complete

# Where to write the distance matrix (in phylip format):
clustering.output.matrix.file=none
# Where to write the clustering tree (newick format):
clustering.output.tree.file=myfile_clusters.dnd
# Where to write the clusters (CSV format):
clustering.output.groups.file=myfile_groups.csv

# Tell if the null distribution of clusters must be computed:
clustering.null=yes
# Number of data sets to simulate:
clustering.null.number=1000
# Where to write the simulated clusters (CSV format):
clustering.null.output.file=myfile_simulation.csv

